{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39b1dfbcab04f168e474d57cbc37054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading .gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc453f1afa04c8bbfb1a9a31f2d7a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading 1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd94a95353af4ea7a78a16adba821ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading README.md:   0%|          | 0.00/90.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a30fd7b2a344206b05472e054b6bd0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/777 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c18991ba5f4f1e8cb2a87471860b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed0c6494b67444991a3d09872d51377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ee2e76084f48c0946a30c15d81a22e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1ca040222e41dba1e8e3beb396c2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a12158b4874665adbd33839e4c31ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc89428b6a1242ff925c1367381c28d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741fd33d751141af84e314aa97a4ef59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1f5a2fba8345a9b4aa5b7d5a93fa46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/jwjung/code/nlp project/pinecone/pinecone langchain.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bjwjung/home/jwjung/code/nlp%20project/pinecone/pinecone%20langchain.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m embeddings \u001b[39m=\u001b[39m HuggingFaceEmbeddings(model_name\u001b[39m=\u001b[39mmodel_name, model_kwargs\u001b[39m=\u001b[39mmodel_kwargs)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bjwjung/home/jwjung/code/nlp%20project/pinecone/pinecone%20langchain.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# upload vector db\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bjwjung/home/jwjung/code/nlp%20project/pinecone/pinecone%20langchain.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m vectordb \u001b[39m=\u001b[39m Pinecone\u001b[39m.\u001b[39mfrom_documents(docs, embeddings, index_name\u001b[39m=\u001b[39mindex_name)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bjwjung/home/jwjung/code/nlp%20project/pinecone/pinecone%20langchain.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m# if already have db \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bjwjung/home/jwjung/code/nlp%20project/pinecone/pinecone%20langchain.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# Pinecone.from_existing_index(index_name, embeddings)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bjwjung/home/jwjung/code/nlp%20project/pinecone/pinecone%20langchain.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bjwjung/home/jwjung/code/nlp%20project/pinecone/pinecone%20langchain.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39m# define llm\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bjwjung/home/jwjung/code/nlp%20project/pinecone/pinecone%20langchain.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m generate_text \u001b[39m=\u001b[39m transformers\u001b[39m.\u001b[39mpipeline(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bjwjung/home/jwjung/code/nlp%20project/pinecone/pinecone%20langchain.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bjwjung/home/jwjung/code/nlp%20project/pinecone/pinecone%20langchain.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m     tokenizer\u001b[39m=\u001b[39mtokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bjwjung/home/jwjung/code/nlp%20project/pinecone/pinecone%20langchain.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m     repetition_penalty\u001b[39m=\u001b[39m\u001b[39m1.1\u001b[39m  \u001b[39m# without this output begins repeating\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bjwjung/home/jwjung/code/nlp%20project/pinecone/pinecone%20langchain.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m ) \u001b[39m# config\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/jw/lib/python3.11/site-packages/langchain/schema/vectorstore.py:438\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m texts \u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    437\u001b[0m metadatas \u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m--> 438\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mfrom_texts(texts, embedding, metadatas\u001b[39m=\u001b[39mmetadatas, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/jw/lib/python3.11/site-packages/langchain/vectorstores/pinecone.py:416\u001b[0m, in \u001b[0;36mPinecone.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, batch_size, text_key, namespace, index_name, upsert_kwargs, pool_threads, embeddings_chunk_size, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m pinecone_index \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mget_pinecone_index(index_name, pool_threads)\n\u001b[1;32m    414\u001b[0m pinecone \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(pinecone_index, embedding, text_key, namespace, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 416\u001b[0m pinecone\u001b[39m.\u001b[39madd_texts(\n\u001b[1;32m    417\u001b[0m     texts,\n\u001b[1;32m    418\u001b[0m     metadatas\u001b[39m=\u001b[39mmetadatas,\n\u001b[1;32m    419\u001b[0m     ids\u001b[39m=\u001b[39mids,\n\u001b[1;32m    420\u001b[0m     namespace\u001b[39m=\u001b[39mnamespace,\n\u001b[1;32m    421\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m    422\u001b[0m     embedding_chunk_size\u001b[39m=\u001b[39membeddings_chunk_size,\n\u001b[1;32m    423\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(upsert_kwargs \u001b[39mor\u001b[39;00m {}),\n\u001b[1;32m    424\u001b[0m )\n\u001b[1;32m    425\u001b[0m \u001b[39mreturn\u001b[39;00m pinecone\n",
      "File \u001b[0;32m/opt/miniconda3/envs/jw/lib/python3.11/site-packages/langchain/vectorstores/pinecone.py:137\u001b[0m, in \u001b[0;36mPinecone.add_texts\u001b[0;34m(self, texts, metadatas, ids, namespace, batch_size, embedding_chunk_size, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m chunk_ids \u001b[39m=\u001b[39m ids[i : i \u001b[39m+\u001b[39m embedding_chunk_size]\n\u001b[1;32m    136\u001b[0m chunk_metadatas \u001b[39m=\u001b[39m metadatas[i : i \u001b[39m+\u001b[39m embedding_chunk_size]\n\u001b[0;32m--> 137\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embed_documents(chunk_texts)\n\u001b[1;32m    138\u001b[0m async_res \u001b[39m=\u001b[39m [\n\u001b[1;32m    139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index\u001b[39m.\u001b[39mupsert(\n\u001b[1;32m    140\u001b[0m         vectors\u001b[39m=\u001b[39mbatch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m     )\n\u001b[1;32m    148\u001b[0m ]\n\u001b[1;32m    149\u001b[0m [res\u001b[39m.\u001b[39mget() \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m async_res]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/jw/lib/python3.11/site-packages/langchain/vectorstores/pinecone.py:84\u001b[0m, in \u001b[0;36mPinecone._embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Embed search docs.\"\"\"\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding, Embeddings):\n\u001b[0;32m---> 84\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding\u001b[39m.\u001b[39membed_documents(\u001b[39mlist\u001b[39m(texts))\n\u001b[1;32m     85\u001b[0m \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m texts]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/jw/lib/python3.11/site-packages/langchain/embeddings/huggingface.py:92\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     90\u001b[0m     sentence_transformers\u001b[39m.\u001b[39mSentenceTransformer\u001b[39m.\u001b[39mstop_multi_process_pool(pool)\n\u001b[1;32m     91\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mencode(texts, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_kwargs)\n\u001b[1;32m     94\u001b[0m \u001b[39mreturn\u001b[39;00m embeddings\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/jw/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:153\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     device \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_target_device\n\u001b[0;32m--> 153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    155\u001b[0m all_embeddings \u001b[39m=\u001b[39m []\n\u001b[1;32m    156\u001b[0m length_sorted_idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margsort([\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_text_length(sen) \u001b[39mfor\u001b[39;00m sen \u001b[39min\u001b[39;00m sentences])\n",
      "File \u001b[0;32m/opt/miniconda3/envs/jw/lib/python3.11/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply(convert)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/jw/lib/python3.11/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/jw/lib/python3.11/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 797 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/jw/lib/python3.11/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/jw/lib/python3.11/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/jw/lib/python3.11/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.document_loaders import TextLoader\n",
    "import transformers\n",
    "import os\n",
    "import pandas as pd\n",
    "import pinecone\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# GT\n",
    "qa = pd.read_csv('./data/gene_qa.csv', encoding='ISO-8859-1')\n",
    "qa = qa[['question','answer']]\n",
    "\n",
    "# external data\n",
    "loader = TextLoader(\"./data/gene_revised.csv\")\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "docs = text_splitter.split_documents(documents) # all_splitters\n",
    "\n",
    "# pinecone setting & upsert\n",
    "PINECONE_API_KEY = '6e7208af-6071-4493-854f-4ea43a3c5d53' # snu 계정 pinecone api_key\n",
    "PINECONE_ENV = 'gcp-starter'\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_ENV\n",
    ")\n",
    "\n",
    "# make pinecone index\n",
    "index_name = 'gene-index'\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=768,\n",
    "        metric='cosine'\n",
    "    )\n",
    "\n",
    "# embedding\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model_kwargs = {\"device\": \"cuda\"}\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
    "\n",
    "# upload vector db\n",
    "vectordb = Pinecone.from_documents(docs, embeddings, index_name=index_name)\n",
    "# if already have db \n",
    "# Pinecone.from_existing_index(index_name, embeddings)\n",
    "\n",
    "# define llm\n",
    "###### model load 필요 ########\n",
    "\n",
    "###########\n",
    "generate_text = transformers.pipeline(\n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=True,  # langchain expects the full text\n",
    "    task='text-generation',\n",
    "    stopping_criteria=stopping_criteria,  # without this model rambles during chat\n",
    "    temperature=0.1,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n",
    "    max_new_tokens=512,  # max number of tokens to generate in the output\n",
    "    repetition_penalty=1.1  # without this output begins repeating\n",
    ") # config\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=generate_text)\n",
    "\n",
    "chain = ConversationalRetrievalChain.from_llm(llm, vectordb.as_retriever(), return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The AAAS gene provides instructions for making a protein called ALADIN whose function is not well understood. Within cells, ALADIN is found in the nuclear envelope, the structure that surrounds the nucleus and separates it from the rest of the cell. Based on its location, ALADIN is thought to be involved in the movement of molecules into and out of the nucleus.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "gene = pd.read_csv('./data/gene_revised.csv')\n",
    "data = gene['description'].tolist()\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_data load code\n",
    "# import json\n",
    "# from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "# with open('gene_url.json', 'r') as file:\n",
    "#    data = json.load(file)\n",
    "# web_links = data\n",
    "# loader = WebBaseLoader(web_links)\n",
    "# documents = loader.load()\n",
    "\n",
    "# #to save loaded documents to csv file\n",
    "# import csv\n",
    "\n",
    "# with open('gene.csv', 'w', newline='') as file:\n",
    "#    writer = csv.writer(file)\n",
    "#    writer.writerow(['col'])\n",
    "#    for item in documents:\n",
    "#        writer.writerow([item])\n",
    "# gene = pd.read_csv('./gene.csv')\n",
    "# data = gene['col'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene data preprocessing code\n",
    "\n",
    "# gene = pd.read_csv('./gene.csv')\n",
    "# data = gene['col'].tolist()\n",
    "\n",
    "# import re\n",
    "\n",
    "# revises = []\n",
    "\n",
    "# for i, d in enumerate(data):\n",
    "#     try:\n",
    "#         start_idx = re.search(r'\\\\nThe',d).start()+2\n",
    "#         revise = d[start_idx:]\n",
    "#         end_idx =re.search(r'\\\\n\\\\n\\\\n\\\\nHealth',revise).start()\n",
    "#         revise = revise[:end_idx]\n",
    "#         revises.append([revise])\n",
    "#     except:\n",
    "#         start_idx = re.search(r'description',e).end() + 3\n",
    "#         r_e = e[start_idx:]\n",
    "#         end_idx = re.search(r'Learn',r_e).start()\n",
    "#         revise = r_e[:end_idx]\n",
    "#         revises.append([revise])\n",
    "\n",
    "\n",
    "# print(revises)\n",
    "\n",
    "# # save to csv\n",
    "\n",
    "# import csv\n",
    "\n",
    "# fields = ['description']\n",
    "\n",
    "# with open('gene_revised.csv', 'w', newline='') as csv_file:\n",
    "#     writer = csv.writer(csv_file)\n",
    "#     writer.writerow(fields)\n",
    "#     writer.writerows(revises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acrodermatitis enteropathica, Birk-Landau-Pere...</td>\n",
       "      <td>Zinc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which of the following would represent a frame...</td>\n",
       "      <td>c.169_170insA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On examination, a patient is noted to have ¡°c...</td>\n",
       "      <td>Urine glycosaminoglycans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A man and a woman have 2 children, both of who...</td>\n",
       "      <td>12.50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An infant was slightly premature and is being ...</td>\n",
       "      <td>Williams syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>The wings of a bat and a bird have similar for...</td>\n",
       "      <td>Analogous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>You are analyzing whole genome sequencing data...</td>\n",
       "      <td>Cornelia de Lange syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>A teen-ager has a several year history of inte...</td>\n",
       "      <td>Dentatorubral-pallidoluysian atrophy (DRPLA)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>In general (and with the caveat that there can...</td>\n",
       "      <td>Dravet syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>You evaluate a young child with very convincin...</td>\n",
       "      <td>11p15 methylation and UPD7 testing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   Acrodermatitis enteropathica, Birk-Landau-Pere...   \n",
       "1   Which of the following would represent a frame...   \n",
       "2   On examination, a patient is noted to have ¡°c...   \n",
       "3   A man and a woman have 2 children, both of who...   \n",
       "4   An infant was slightly premature and is being ...   \n",
       "..                                                ...   \n",
       "79  The wings of a bat and a bird have similar for...   \n",
       "80  You are analyzing whole genome sequencing data...   \n",
       "81  A teen-ager has a several year history of inte...   \n",
       "82  In general (and with the caveat that there can...   \n",
       "83  You evaluate a young child with very convincin...   \n",
       "\n",
       "                                           answer  \n",
       "0                                            Zinc  \n",
       "1                                   c.169_170insA  \n",
       "2                        Urine glycosaminoglycans  \n",
       "3                                          12.50%  \n",
       "4                               Williams syndrome  \n",
       "..                                            ...  \n",
       "79                                      Analogous  \n",
       "80                     Cornelia de Lange syndrome  \n",
       "81  Dentatorubral-pallidoluysian atrophy (DRPLA)  \n",
       "82                                Dravet syndrome  \n",
       "83             11p15 methylation and UPD7 testing  \n",
       "\n",
       "[84 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "qa = pd.read_csv('./gene_qa.csv', encoding='ISO-8859-1')\n",
    "qa = qa[['question','answer']]\n",
    "qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.node_parser import SimpleNodeParser\n",
    "\n",
    "parser = SimpleNodeParser.from_defaults()\n",
    "nodes = parser.get_nodes_from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ABCA12 gene provides instructions for making a protein known as an ATP-binding cassette (ABC) transporter. This information is mentioned in the document.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is ABCA12 gene? if you refer document, please answer with reference part\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = SummaryIndex.from_documents(docs)\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is ABCA12 gene? \")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
